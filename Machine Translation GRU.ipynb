{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Machine Translation GRU.ipynb","provenance":[],"authorship_tag":"ABX9TyPkkZyR6JUfCm/yA2X/9dNE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"scnIQaa5u4QY"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"yf6kGzAm8xuO"},"source":["# ***Machine Translation using GRU***\r\n","\r\n","Preprocess - You'll convert text to sequence of integers.\r\n","Models Create models which accepts a sequence of integers as input and returns a probability distribution over possible translations. After learning about the basic types of neural networks that are often used for machine translation, you will engage in your own investigations, to design your own model!\r\n","Prediction Run the model on English text."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nkHzfr4I4Bnc","executionInfo":{"status":"ok","timestamp":1609753058060,"user_tz":-330,"elapsed":26842,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}},"outputId":"0627ee9d-4cdd-41f1-fe4d-104601ba657e"},"source":["# mount the google drive\r\n","from google.colab import drive\r\n","drive.mount('/content/gdrive')\r\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"awfO5W_6io_D","executionInfo":{"status":"ok","timestamp":1609753066810,"user_tz":-330,"elapsed":3296,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}}},"source":["import sys\r\n","import os\r\n","# get the directory where all the data files and python and necessary files are stored\r\n","py_file_location = \"/content/gdrive/My Drive/Colab Notebooks/\"\r\n","sys.path.append(os.path.abspath(py_file_location)) "],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"FlyRWmHghZaf","executionInfo":{"status":"ok","timestamp":1609753066813,"user_tz":-330,"elapsed":1658,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}}},"source":["#%load_ext autoreload\r\n","#%aimport helper, tests\r\n","#%autoreload 1"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"o8x_FvoW8dHI","executionInfo":{"status":"ok","timestamp":1609753074223,"user_tz":-330,"elapsed":6435,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}}},"source":["import collections\r\n","\r\n","import helper\r\n","import numpy as np\r\n","import project_tests as tests\r\n","\r\n","from keras.preprocessing.text import Tokenizer\r\n","from keras.preprocessing.sequence import pad_sequences\r\n","from keras.models import Model, Sequential\r\n","from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, Dropout, LSTM\r\n","from keras.layers.embeddings import Embedding\r\n","from keras.optimizers import Adam\r\n","from keras.losses import sparse_categorical_crossentropy"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HSreOOvc9iZF","executionInfo":{"status":"ok","timestamp":1609753078868,"user_tz":-330,"elapsed":8423,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}},"outputId":"12c56a82-b5f4-4dd4-8a3a-05e86ea39167"},"source":["# Verify Access to GPU\r\n","\r\n","from tensorflow.python.client import device_lib\r\n","print(device_lib.list_local_devices())"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 13046652970567456781\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 14638920512\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 755964087271032125\n","physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n","]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d1Iq1sRtmEIY","executionInfo":{"status":"ok","timestamp":1609753104389,"user_tz":-330,"elapsed":2574,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}},"outputId":"9e520ab7-b5e0-4d5d-9c3b-1ccbd7823c3e"},"source":["# Load English data\r\n","import importlib # this is to relaod the imported library \r\n","importlib.reload(helper)\r\n","english_sentences = helper.load_data('/content/gdrive/My Drive/Colab Notebooks/small_vocab_en.txt')\r\n","# Load French data\r\n","french_sentences = helper.load_data('/content/gdrive/My Drive/Colab Notebooks/small_vocab_fr.txt')\r\n","print('Dataset Loaded')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Dataset Loaded\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pXDhE-dmoZiE","executionInfo":{"status":"ok","timestamp":1609753106836,"user_tz":-330,"elapsed":1112,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}},"outputId":"4d3bc729-d015-4a4d-ba7d-c9223627f785"},"source":["for sample_i in range(5):\n","    print('English sample {}:  {}'.format(sample_i + 1, english_sentences[sample_i]))\n","    print('French sample {}:  {}\\n'.format(sample_i + 1, french_sentences[sample_i]))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["English sample 1:  new jersey is sometimes quiet during autumn , and it is snowy in april .\n","French sample 1:  new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n","\n","English sample 2:  the united states is usually chilly during july , and it is usually freezing in november .\n","French sample 2:  les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n","\n","English sample 3:  california is usually quiet during march , and it is usually hot in june .\n","French sample 3:  california est généralement calme en mars , et il est généralement chaud en juin .\n","\n","English sample 4:  the united states is sometimes mild during june , and it is cold in september .\n","French sample 4:  les états-unis est parfois légère en juin , et il fait froid en septembre .\n","\n","English sample 5:  your least liked fruit is the grape , but my least liked is the apple .\n","French sample 5:  votre moins aimé fruit est le raisin , mais mon moins aimé est la pomme .\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_dwoDw3Xm2NC","executionInfo":{"status":"ok","timestamp":1609753110764,"user_tz":-330,"elapsed":1715,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}},"outputId":"38b9c9ae-ff69-46d5-b901-71eed6deebe6"},"source":["# create a vocabulary\r\n","english_words_counter = collections.Counter([word for sentence in english_sentences for word in sentence.split()])\r\n","french_words_counter = collections.Counter([word for sentence in french_sentences for word in sentence.split()])\r\n","#type(english_words_counter)\r\n","print('{} English words.'.format(len([word for sentence in english_sentences for word in sentence.split()])))\r\n","print('{} unique English words.'.format(len(english_words_counter))) # len on collection counter gives uinque values length\r\n","\r\n","print('10 Most common words in the English dataset:')\r\n","print('\"' + '\" \"'.join(list(zip(*english_words_counter.most_common(10)))[0]) + '\"')\r\n","print()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["1823250 English words.\n","227 unique English words.\n","10 Most common words in the English dataset:\n","\"is\" \",\" \".\" \"in\" \"it\" \"during\" \"the\" \"but\" \"and\" \"sometimes\"\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P2B2-LCHAtVE","executionInfo":{"status":"ok","timestamp":1609753125999,"user_tz":-330,"elapsed":1400,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}},"outputId":"d4c27a4c-afbc-4835-9024-43f7a20021a8"},"source":["print(english_words_counter ) # collections.counter gives the count of each word in the list"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Counter({'is': 205858, ',': 140897, '.': 129039, 'in': 75525, 'it': 75137, 'during': 74933, 'the': 67628, 'but': 63987, 'and': 59850, 'sometimes': 37746, 'usually': 37507, 'never': 37500, 'least': 27564, 'favorite': 27371, 'fruit': 27105, 'most': 14934, 'loved': 13666, 'liked': 13546, 'new': 12197, 'paris': 11334, 'india': 11277, 'united': 11270, 'states': 11270, 'california': 11250, 'jersey': 11225, 'france': 11170, 'china': 10953, 'he': 10786, 'she': 10786, 'grapefruit': 10118, 'your': 9734, 'my': 9700, 'his': 9700, 'her': 9700, 'fall': 9134, 'june': 9133, 'spring': 9102, 'january': 9090, 'winter': 9038, 'march': 9023, 'autumn': 9004, 'may': 8995, 'nice': 8984, 'september': 8958, 'july': 8956, 'april': 8954, 'november': 8951, 'summer': 8948, 'december': 8945, 'february': 8942, 'our': 8932, 'their': 8932, 'freezing': 8928, 'pleasant': 8916, 'beautiful': 8915, 'october': 8910, 'snowy': 8898, 'warm': 8890, 'cold': 8878, 'wonderful': 8808, 'dry': 8794, 'busy': 8791, 'august': 8789, 'chilly': 8770, 'rainy': 8761, 'mild': 8743, 'wet': 8726, 'relaxing': 8696, 'quiet': 8693, 'hot': 8639, 'dislikes': 7314, 'likes': 7314, 'limes': 5554, 'mangoes': 5549, 'lemons': 5533, 'grapes': 5525, 'apples': 5452, 'oranges': 5452, 'strawberries': 5452, 'bananas': 5452, 'peaches': 5451, 'pears': 5451, 'to': 5166, 'strawberry': 4715, 'grape': 4703, 'lime': 4680, 'apple': 4652, 'lemon': 4652, 'banana': 4652, 'mango': 4652, 'pear': 4652, 'peach': 4652, 'orange': 4651, 'like': 4588, 'dislike': 4444, 'they': 3222, 'that': 2712, 'i': 2664, 'we': 2532, 'you': 2414, 'animal': 2304, 'a': 1944, 'truck': 1944, 'car': 1944, 'automobile': 1944, 'was': 1867, 'next': 1666, 'go': 1386, 'driving': 1296, 'visit': 1224, 'little': 1016, 'big': 1016, 'old': 972, 'yellow': 972, 'red': 972, 'rusty': 972, 'blue': 972, 'white': 972, 'black': 972, 'green': 972, 'shiny': 972, 'favorite.': 961, 'are': 870, '?': 811, 'last': 781, 'feared': 768, 'animals': 768, 'this': 768, 'plan': 714, 'going': 666, 'saw': 648, 'disliked': 648, 'drives': 648, 'drove': 648, 'grapefruit.': 574, 'between': 540, 'liked.': 500, 'loved.': 500, 'translate': 480, 'plans': 476, 'peaches.': 393, 'pears.': 393, 'bananas.': 392, 'oranges.': 392, 'apples.': 392, 'strawberries.': 392, 'were': 384, 'went': 378, 'might': 378, 'wanted': 378, 'thinks': 360, 'grapes.': 319, 'spanish': 312, 'portuguese': 312, 'chinese': 312, 'english': 312, 'french': 312, 'lemons.': 311, 'translating': 300, 'mangoes.': 295, 'limes.': 290, 'difficult': 260, 'fun': 260, 'easy': 260, 'wants': 252, 'think': 240, 'why': 240, \"it's\": 240, 'did': 204, 'orange.': 197, 'mango.': 196, 'banana.': 196, 'peach.': 196, 'lemon.': 196, 'pear.': 196, 'apple.': 196, 'cat': 192, 'shark': 192, 'bird': 192, 'mouse': 192, 'horse': 192, 'elephant': 192, 'dog': 192, 'monkey': 192, 'lion': 192, 'bear': 192, 'rabbit': 192, 'snake': 192, 'lime.': 168, 'grape.': 145, 'when': 144, 'strawberry.': 133, 'want': 126, 'fruit.': 87, 'do': 84, 'how': 67, 'elephants': 64, 'horses': 64, 'dogs': 64, 'sharks': 64, 'snakes': 64, 'cats': 64, 'rabbits': 64, 'monkeys': 64, 'bears': 64, 'birds': 64, 'lions': 64, 'mice': 64, \"didn't\": 60, 'eiffel': 57, 'tower': 57, 'grocery': 57, 'store': 57, 'football': 57, 'field': 57, 'lake': 57, 'school': 57, 'would': 48, \"aren't\": 36, 'been': 36, 'weather': 33, 'does': 24, 'has': 24, \"isn't\": 24, 'am': 24, 'where': 12, 'have': 12})\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W3G-IWPvB79Q","executionInfo":{"status":"ok","timestamp":1609753129578,"user_tz":-330,"elapsed":1115,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}},"outputId":"78f4f453-28cf-4424-98ff-7d632bbb2be8"},"source":["print('{} French words.'.format(len([word for sentence in french_sentences for word in sentence.split()])))\r\n","print('{} unique French words.'.format(len(french_words_counter)))\r\n","print('10 Most common words in the French dataset:')\r\n","print('\"' + '\" \"'.join(list(zip(*french_words_counter.most_common(10)))[0]) + '\"')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["1961295 French words.\n","355 unique French words.\n","10 Most common words in the French dataset:\n","\"est\" \".\" \",\" \"en\" \"il\" \"les\" \"mais\" \"et\" \"la\" \"parfois\"\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KEQ0LfjgC1u-","executionInfo":{"status":"ok","timestamp":1609753131624,"user_tz":-330,"elapsed":1012,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}}},"source":["## Data Preprocessing\r\n","# Convert to tokens\r\n","# pad the token to make all sentences of equal length\r\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"6X6XHriqaFKL","executionInfo":{"status":"ok","timestamp":1609753286086,"user_tz":-330,"elapsed":1231,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}}},"source":["# tokenization using the keras \r\n","def tokenize(x):\r\n","    \"\"\"\r\n","    Tokenize x\r\n","    :param x: List of sentences/strings to be tokenized\r\n","    :return: Tuple of (tokenized x data, tokenizer used to tokenize x)\r\n","    \"\"\"\r\n","    # TODO: Implement\r\n","    tokenizer = Tokenizer()\r\n","    tokenizer.fit_on_texts(x)\r\n","    return tokenizer.texts_to_sequences(x), tokenizer\r\n","\r\n","tests.test_tokenize(tokenize)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F87MTRaNxdCu","executionInfo":{"status":"ok","timestamp":1609754813511,"user_tz":-330,"elapsed":1244,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}},"outputId":"93f98cbf-ca65-49f2-bd1c-b5ebab3bea20"},"source":["# Tokenize Example output\r\n","text_sentences = [\r\n","    'The quick brown fox jumps over the lazy dog .',\r\n","    'By Jove , my quick study of lexicography won a prize .',\r\n","    'This is a short sentence .']\r\n","text_tokenized, text_tokenizer = tokenize(text_sentences)\r\n","print(text_tokenizer.word_index)\r\n","print()\r\n","for sample_i, (sent, token_sent) in enumerate(zip(text_sentences, text_tokenized)):\r\n","    print('Sequence {} in x'.format(sample_i + 1))\r\n","    print('  Input:  {}'.format(sent))\r\n","    print('  Output: {}'.format(token_sent))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["{'the': 1, 'quick': 2, 'a': 3, 'brown': 4, 'fox': 5, 'jumps': 6, 'over': 7, 'lazy': 8, 'dog': 9, 'by': 10, 'jove': 11, 'my': 12, 'study': 13, 'of': 14, 'lexicography': 15, 'won': 16, 'prize': 17, 'this': 18, 'is': 19, 'short': 20, 'sentence': 21}\n","\n","Sequence 1 in x\n","  Input:  The quick brown fox jumps over the lazy dog .\n","  Output: [1, 2, 4, 5, 6, 7, 1, 8, 9]\n","Sequence 2 in x\n","  Input:  By Jove , my quick study of lexicography won a prize .\n","  Output: [10, 11, 12, 2, 13, 14, 15, 16, 3, 17]\n","Sequence 3 in x\n","  Input:  This is a short sentence .\n","  Output: [18, 19, 3, 20, 21]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nzA1eqE2xpGK","executionInfo":{"status":"ok","timestamp":1609755007996,"user_tz":-330,"elapsed":1204,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}},"outputId":"aa01679d-2ac2-4a9f-ea3e-01c47727bdf9"},"source":["# Padding : to have all the tokenized sentenences of equal length\r\n","def pad(x, length=None):\r\n","    \"\"\"\r\n","    Pad x\r\n","    :param x: List of sequences.\r\n","    :param length: Length to pad the sequence to.  If None, use length of longest sequence in x.\r\n","    :return: Padded numpy array of sequences\r\n","    \"\"\"\r\n","    # TODO: Implement\r\n","    return pad_sequences(x, maxlen=length, padding='post')\r\n","\r\n","tests.test_pad(pad)\r\n","\r\n","# Pad Tokenized output\r\n","test_pad = pad(text_tokenized)\r\n","for sample_i, (token_sent, pad_sent) in enumerate(zip(text_tokenized, test_pad)):\r\n","    print('Sequence {} in x'.format(sample_i + 1))\r\n","    print('  Input:  {}'.format(np.array(token_sent)))\r\n","    print('  Output: {}'.format(pad_sent))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Sequence 1 in x\n","  Input:  [1 2 4 5 6 7 1 8 9]\n","  Output: [1 2 4 5 6 7 1 8 9 0]\n","Sequence 2 in x\n","  Input:  [10 11 12  2 13 14 15 16  3 17]\n","  Output: [10 11 12  2 13 14 15 16  3 17]\n","Sequence 3 in x\n","  Input:  [18 19  3 20 21]\n","  Output: [18 19  3 20 21  0  0  0  0  0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9hFbfF7-4Bb3","executionInfo":{"status":"ok","timestamp":1609757212582,"user_tz":-330,"elapsed":9295,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}},"outputId":"354390b0-2941-4f95-b447-31a97813bae0"},"source":["## Preprocess pipeline\r\n","def preprocess(x, y):\r\n","    \"\"\"\r\n","    Preprocess x and y\r\n","    :param x: Feature List of sentences\r\n","    :param y: Label List of sentences\r\n","    :return: Tuple of (Preprocessed x, Preprocessed y, x tokenizer, y tokenizer)\r\n","    \"\"\"\r\n","    preprocess_x, x_tk = tokenize(x)\r\n","    preprocess_y, y_tk = tokenize(y)\r\n","\r\n","    preprocess_x = pad(preprocess_x)\r\n","    preprocess_y = pad(preprocess_y)\r\n","\r\n","    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\r\n","    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\r\n","\r\n","    return preprocess_x, preprocess_y, x_tk, y_tk\r\n","\r\n","preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer =\\\r\n","    preprocess(english_sentences, french_sentences)\r\n","    \r\n","max_english_sequence_length = preproc_english_sentences.shape[1]\r\n","max_french_sequence_length = preproc_french_sentences.shape[1]\r\n","english_vocab_size = len(english_tokenizer.word_index)\r\n","french_vocab_size = len(french_tokenizer.word_index)\r\n","\r\n","print('Data Preprocessed')\r\n","print(\"Max English sentence length:\", max_english_sequence_length)\r\n","print(\"Max French sentence length:\", max_french_sequence_length)\r\n","print(\"English vocabulary size:\", english_vocab_size)\r\n","print(\"French vocabulary size:\", french_vocab_size)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Data Preprocessed\n","Max English sentence length: 15\n","Max French sentence length: 21\n","English vocabulary size: 199\n","French vocabulary size: 344\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"p6K4-2gZ6OdG","executionInfo":{"status":"ok","timestamp":1609755806512,"user_tz":-330,"elapsed":1469,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}}},"source":["# Models\r\n","#In this section, you will experiment with various neural network architectures. You will begin by training four relatively simple architectures.\r\n","\r\n","#Model 1 is a simple RNN\r\n","#Model 2 is a RNN with Embedding\r\n","#Model 3 is a Bidirectional RNN\r\n","#Model 4 is an optional Encoder-Decoder RNN"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Az3LefTl7EUt","executionInfo":{"status":"ok","timestamp":1609755810248,"user_tz":-330,"elapsed":1377,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}},"outputId":"945f8eb5-013a-4515-e037-f073dc101797"},"source":["def logits_to_text(logits, tokenizer):\r\n","    \"\"\"\r\n","    Turn logits from a neural network into text using the tokenizer\r\n","    :param logits: Logits from a neural network\r\n","    :param tokenizer: Keras Tokenizer fit on the labels\r\n","    :return: String that represents the text of the logits\r\n","    \"\"\"\r\n","    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\r\n","    index_to_words[0] = '<PAD>'\r\n","\r\n","    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\r\n","\r\n","print('`logits_to_text` function loaded.')"],"execution_count":19,"outputs":[{"output_type":"stream","text":["`logits_to_text` function loaded.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GjxUKP7l7FQw","executionInfo":{"status":"ok","timestamp":1609757819762,"user_tz":-330,"elapsed":1064,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}}},"source":["#A basic RNN model is a good baseline for sequence data. In this model, you'll build a RNN that translates English to French.\r\n","def simple_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\r\n","    \"\"\"\r\n","    Build and train a basic RNN on x and y\r\n","    :param input_shape: Tuple of input shape\r\n","    :param output_sequence_length: Length of output sequence\r\n","    :param english_vocab_size: Number of unique English words in the dataset\r\n","    :param french_vocab_size: Number of unique French words in the dataset\r\n","    :return: Keras model built, but not trained\r\n","    \"\"\"\r\n","    # Hyperparameters\r\n","    learning_rate = 0.005\r\n","    \r\n","    # TODO: Build the layers\r\n","    model = Sequential()\r\n","    model.add(GRU(256, input_shape=input_shape[1:], return_sequences=True))\r\n","    model.add(TimeDistributed(Dense(1024, activation='relu')))\r\n","    model.add(Dropout(0.5))\r\n","    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax'))) \r\n","\r\n","    # Compile model\r\n","    model.compile(loss=sparse_categorical_crossentropy,\r\n","                  optimizer=Adam(learning_rate),\r\n","                  metrics=['accuracy'])\r\n","    return model\r\n","\r\n"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P5bkG7nYATIT","executionInfo":{"status":"ok","timestamp":1609757967137,"user_tz":-330,"elapsed":65339,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}},"outputId":"e2380d79-87f3-4816-8314-9a253495066c"},"source":["# Reshaping the input to work with a basic RNN\r\n","tmp_x = pad(preproc_english_sentences, max_french_sequence_length)\r\n","tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2], 1))\r\n","\r\n","# Train the neural network\r\n","simple_rnn_model = simple_model(\r\n","    tmp_x.shape,\r\n","    max_french_sequence_length,\r\n","    english_vocab_size,\r\n","    french_vocab_size)\r\n","\r\n","print(simple_rnn_model.summary())\r\n","\r\n","simple_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=10, validation_split=0.2)\r\n","\r\n","# Print prediction(s)\r\n","print(logits_to_text(simple_rnn_model.predict(tmp_x[:1])[0], french_tokenizer))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","gru_1 (GRU)                  (None, 21, 256)           198912    \n","_________________________________________________________________\n","time_distributed_2 (TimeDist (None, 21, 1024)          263168    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 21, 1024)          0         \n","_________________________________________________________________\n","time_distributed_3 (TimeDist (None, 21, 344)           352600    \n","=================================================================\n","Total params: 814,680\n","Trainable params: 814,680\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/10\n","108/108 [==============================] - 14s 55ms/step - loss: 2.6052 - accuracy: 0.4703 - val_loss: nan - val_accuracy: 0.6321\n","Epoch 2/10\n","108/108 [==============================] - 5s 51ms/step - loss: 1.3010 - accuracy: 0.6289 - val_loss: nan - val_accuracy: 0.6766\n","Epoch 3/10\n","108/108 [==============================] - 5s 51ms/step - loss: 1.1249 - accuracy: 0.6643 - val_loss: nan - val_accuracy: 0.6920\n","Epoch 4/10\n","108/108 [==============================] - 5s 51ms/step - loss: 1.0307 - accuracy: 0.6806 - val_loss: nan - val_accuracy: 0.7111\n","Epoch 5/10\n","108/108 [==============================] - 6s 51ms/step - loss: 0.9704 - accuracy: 0.6924 - val_loss: nan - val_accuracy: 0.7102\n","Epoch 6/10\n","108/108 [==============================] - 6s 51ms/step - loss: 0.9354 - accuracy: 0.6970 - val_loss: nan - val_accuracy: 0.7311\n","Epoch 7/10\n","108/108 [==============================] - 6s 51ms/step - loss: 0.8793 - accuracy: 0.7140 - val_loss: nan - val_accuracy: 0.7068\n","Epoch 8/10\n","108/108 [==============================] - 6s 51ms/step - loss: 0.8466 - accuracy: 0.7221 - val_loss: nan - val_accuracy: 0.7573\n","Epoch 9/10\n","108/108 [==============================] - 6s 52ms/step - loss: 0.7966 - accuracy: 0.7385 - val_loss: nan - val_accuracy: 0.7316\n","Epoch 10/10\n","108/108 [==============================] - 6s 52ms/step - loss: 0.9017 - accuracy: 0.7147 - val_loss: nan - val_accuracy: 0.7550\n","new jersey est parfois chaud en l' et il est est en en <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UV0C2zWHDEOe","executionInfo":{"status":"ok","timestamp":1609758591493,"user_tz":-330,"elapsed":1359,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}},"outputId":"a55c014b-b7da-4df6-9bb5-fd144a0fb9d9"},"source":["# Print prediction(s)\r\n","print(\"Prediction:\")\r\n","print(logits_to_text(simple_rnn_model.predict(tmp_x[:1])[0], french_tokenizer))\r\n","\r\n","print(\"\\nCorrect Translation:\")\r\n","print(french_sentences[:1])\r\n","\r\n","print(\"\\nOriginal text:\")\r\n","print(english_sentences[:1])"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Prediction:\n","new jersey est parfois chaud en l' et il est est en en <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n","\n","Correct Translation:\n","[\"new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\"]\n","\n","Original text:\n","['new jersey is sometimes quiet during autumn , and it is snowy in april .']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V3QuSy7kFsQq","executionInfo":{"status":"ok","timestamp":1609758749805,"user_tz":-330,"elapsed":1171,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}}},"source":["# RNN model using word embedding\r\n","def embed_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\r\n","    \"\"\"\r\n","    Build and train a RNN model using word embedding on x and y\r\n","    :param input_shape: Tuple of input shape\r\n","    :param output_sequence_length: Length of output sequence\r\n","    :param english_vocab_size: Number of unique English words in the dataset\r\n","    :param french_vocab_size: Number of unique French words in the dataset\r\n","    :return: Keras model built, but not trained\r\n","    \"\"\"\r\n","    # TODO: Implement\r\n","\r\n","    # Hyperparameters\r\n","    learning_rate = 0.005\r\n","    \r\n","    # TODO: Build the layers\r\n","    model = Sequential()\r\n","    model.add(Embedding(english_vocab_size, 256, input_length=input_shape[1], input_shape=input_shape[1:]))\r\n","    model.add(GRU(256, return_sequences=True))    \r\n","    model.add(TimeDistributed(Dense(1024, activation='relu')))\r\n","    model.add(Dropout(0.5))\r\n","    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax'))) \r\n","\r\n","    # Compile model\r\n","    model.compile(loss=sparse_categorical_crossentropy,\r\n","                  optimizer=Adam(learning_rate),\r\n","                  metrics=['accuracy'])\r\n","    return model"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S1MFdrzMGS-W","executionInfo":{"status":"ok","timestamp":1609758862772,"user_tz":-330,"elapsed":75375,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}},"outputId":"5c57b79d-36d2-4054-e009-29f2159332cb"},"source":["# TODO: Reshape the input\r\n","tmp_x = pad(preproc_english_sentences, preproc_french_sentences.shape[1])\r\n","tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2]))\r\n","\r\n","# TODO: Train the neural network\r\n","embed_rnn_model = embed_model(\r\n","    tmp_x.shape,\r\n","    preproc_french_sentences.shape[1],\r\n","    len(english_tokenizer.word_index)+1,\r\n","    len(french_tokenizer.word_index)+1)\r\n","\r\n","embed_rnn_model.summary()\r\n","\r\n","embed_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=10, validation_split=0.2)\r\n","\r\n","# TODO: Print prediction(s)\r\n","print(logits_to_text(embed_rnn_model.predict(tmp_x[:1])[0], french_tokenizer))\r\n"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, 21, 256)           51200     \n","_________________________________________________________________\n","gru_2 (GRU)                  (None, 21, 256)           394752    \n","_________________________________________________________________\n","time_distributed_4 (TimeDist (None, 21, 1024)          263168    \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 21, 1024)          0         \n","_________________________________________________________________\n","time_distributed_5 (TimeDist (None, 21, 345)           353625    \n","=================================================================\n","Total params: 1,062,745\n","Trainable params: 1,062,745\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","108/108 [==============================] - 9s 69ms/step - loss: 2.3337 - accuracy: 0.5479 - val_loss: 0.5063 - val_accuracy: 0.8349\n","Epoch 2/10\n","108/108 [==============================] - 7s 66ms/step - loss: 0.4785 - accuracy: 0.8440 - val_loss: 0.3141 - val_accuracy: 0.8950\n","Epoch 3/10\n","108/108 [==============================] - 7s 66ms/step - loss: 0.3185 - accuracy: 0.8941 - val_loss: 0.2430 - val_accuracy: 0.9170\n","Epoch 4/10\n","108/108 [==============================] - 7s 66ms/step - loss: 0.2517 - accuracy: 0.9152 - val_loss: 0.2210 - val_accuracy: 0.9243\n","Epoch 5/10\n","108/108 [==============================] - 7s 66ms/step - loss: 0.2263 - accuracy: 0.9227 - val_loss: 0.2062 - val_accuracy: 0.9279\n","Epoch 6/10\n","108/108 [==============================] - 7s 66ms/step - loss: 0.2096 - accuracy: 0.9274 - val_loss: 0.1937 - val_accuracy: 0.9333\n","Epoch 7/10\n","108/108 [==============================] - 7s 66ms/step - loss: 0.1972 - accuracy: 0.9311 - val_loss: 0.1888 - val_accuracy: 0.9337\n","Epoch 8/10\n","108/108 [==============================] - 7s 66ms/step - loss: 0.1899 - accuracy: 0.9327 - val_loss: 0.1908 - val_accuracy: 0.9338\n","Epoch 9/10\n","108/108 [==============================] - 7s 66ms/step - loss: 0.1851 - accuracy: 0.9344 - val_loss: 0.1837 - val_accuracy: 0.9355\n","Epoch 10/10\n","108/108 [==============================] - 7s 66ms/step - loss: 0.1783 - accuracy: 0.9364 - val_loss: 0.1869 - val_accuracy: 0.9347\n","new jersey est parfois calme en l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rE1flYeaGcb9","executionInfo":{"status":"ok","timestamp":1609758877846,"user_tz":-330,"elapsed":1285,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}},"outputId":"75383806-e996-43f3-979c-f20f6a0bdd4c"},"source":["# Print prediction(s)\r\n","print(\"Prediction:\")\r\n","print(logits_to_text(embed_rnn_model.predict(tmp_x[:1])[0], french_tokenizer))\r\n","\r\n","print(\"\\nCorrect Translation:\")\r\n","print(french_sentences[:1])\r\n","\r\n","print(\"\\nOriginal text:\")\r\n","print(english_sentences[:1])"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Prediction:\n","new jersey est parfois calme en l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n","\n","Correct Translation:\n","[\"new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\"]\n","\n","Original text:\n","['new jersey is sometimes quiet during autumn , and it is snowy in april .']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xhS46A5ZGyNV","executionInfo":{"status":"ok","timestamp":1609758966156,"user_tz":-330,"elapsed":1433,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}}},"source":["# Bidirectional RNNs\r\n","# One restriction of a RNN is that it can't see the future input, only the past. This is where bidirectional recurrent neural networks come in. They are able to see the future data.\r\n","def bd_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\r\n","    \"\"\"\r\n","    Build and train a bidirectional RNN model on x and y\r\n","    :param input_shape: Tuple of input shape\r\n","    :param output_sequence_length: Length of output sequence\r\n","    :param english_vocab_size: Number of unique English words in the dataset\r\n","    :param french_vocab_size: Number of unique French words in the dataset\r\n","    :return: Keras model built, but not trained\r\n","    \"\"\"\r\n","    # TODO: Implement\r\n","\r\n","    # Hyperparameters\r\n","    learning_rate = 0.003\r\n","    \r\n","    # TODO: Build the layers\r\n","    model = Sequential()\r\n","    model.add(Bidirectional(GRU(128, return_sequences=True), input_shape=input_shape[1:]))\r\n","    model.add(TimeDistributed(Dense(1024, activation='relu')))\r\n","    model.add(Dropout(0.5))\r\n","    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax'))) \r\n","\r\n","    # Compile model\r\n","    model.compile(loss=sparse_categorical_crossentropy,\r\n","                  optimizer=Adam(learning_rate),\r\n","                  metrics=['accuracy'])\r\n","    return model"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I80SsDN_HHu6","executionInfo":{"status":"ok","timestamp":1609759063277,"user_tz":-330,"elapsed":75228,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}},"outputId":"ea9443aa-69f6-439d-c917-cf9fff44d5dd"},"source":["# TODO: Reshape the input\r\n","tmp_x = pad(preproc_english_sentences, preproc_french_sentences.shape[1])\r\n","tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2]))\r\n","\r\n","# TODO: Train and Print prediction(s)\r\n","embed_rnn_model = embed_model(\r\n","    tmp_x.shape,\r\n","    preproc_french_sentences.shape[1],\r\n","    len(english_tokenizer.word_index)+1,\r\n","    len(french_tokenizer.word_index)+1)\r\n","\r\n","embed_rnn_model.summary()\r\n","\r\n","embed_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=10, validation_split=0.2)\r\n","\r\n","print(logits_to_text(embed_rnn_model.predict(tmp_x[:1])[0], french_tokenizer))"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, 21, 256)           51200     \n","_________________________________________________________________\n","gru_3 (GRU)                  (None, 21, 256)           394752    \n","_________________________________________________________________\n","time_distributed_6 (TimeDist (None, 21, 1024)          263168    \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 21, 1024)          0         \n","_________________________________________________________________\n","time_distributed_7 (TimeDist (None, 21, 345)           353625    \n","=================================================================\n","Total params: 1,062,745\n","Trainable params: 1,062,745\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","108/108 [==============================] - 9s 69ms/step - loss: 2.3324 - accuracy: 0.5467 - val_loss: 0.4748 - val_accuracy: 0.8469\n","Epoch 2/10\n","108/108 [==============================] - 7s 66ms/step - loss: 0.4526 - accuracy: 0.8521 - val_loss: 0.3009 - val_accuracy: 0.8980\n","Epoch 3/10\n","108/108 [==============================] - 7s 66ms/step - loss: 0.3050 - accuracy: 0.8980 - val_loss: 0.2416 - val_accuracy: 0.9169\n","Epoch 4/10\n","108/108 [==============================] - 7s 66ms/step - loss: 0.2509 - accuracy: 0.9149 - val_loss: 0.2162 - val_accuracy: 0.9257\n","Epoch 5/10\n","108/108 [==============================] - 7s 66ms/step - loss: 0.2201 - accuracy: 0.9245 - val_loss: 0.2006 - val_accuracy: 0.9293\n","Epoch 6/10\n","108/108 [==============================] - 7s 66ms/step - loss: 0.2050 - accuracy: 0.9287 - val_loss: 0.1986 - val_accuracy: 0.9312\n","Epoch 7/10\n","108/108 [==============================] - 7s 66ms/step - loss: 0.1969 - accuracy: 0.9310 - val_loss: 0.1889 - val_accuracy: 0.9338\n","Epoch 8/10\n","108/108 [==============================] - 7s 66ms/step - loss: 0.1879 - accuracy: 0.9334 - val_loss: 0.1958 - val_accuracy: 0.9326\n","Epoch 9/10\n","108/108 [==============================] - 7s 66ms/step - loss: 0.1864 - accuracy: 0.9342 - val_loss: 0.1817 - val_accuracy: 0.9362\n","Epoch 10/10\n","108/108 [==============================] - 7s 66ms/step - loss: 0.1774 - accuracy: 0.9364 - val_loss: 0.1798 - val_accuracy: 0.9364\n","new jersey est parfois calme en l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0VuG6el0HNbc","executionInfo":{"status":"ok","timestamp":1609759107109,"user_tz":-330,"elapsed":1668,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}},"outputId":"d04fdd61-b142-4236-8ad9-38564fc2f50d"},"source":["# Print prediction(s)\r\n","print(\"Prediction:\")\r\n","print(logits_to_text(embed_rnn_model.predict(tmp_x[:1])[0], french_tokenizer))\r\n","\r\n","print(\"\\nCorrect Translation:\")\r\n","print(french_sentences[:1])\r\n","\r\n","print(\"\\nOriginal text:\")\r\n","print(english_sentences[:1])"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Prediction:\n","new jersey est parfois calme en l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n","\n","Correct Translation:\n","[\"new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\"]\n","\n","Original text:\n","['new jersey is sometimes quiet during autumn , and it is snowy in april .']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0NxFpms6HqFZ","executionInfo":{"status":"ok","timestamp":1609759206854,"user_tz":-330,"elapsed":1073,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}}},"source":["# Encoder-Decoder\r\n","def encdec_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\r\n","    \"\"\"\r\n","    Build and train an encoder-decoder model on x and y\r\n","    :param input_shape: Tuple of input shape\r\n","    :param output_sequence_length: Length of output sequence\r\n","    :param english_vocab_size: Number of unique English words in the dataset\r\n","    :param french_vocab_size: Number of unique French words in the dataset\r\n","    :return: Keras model built, but not trained\r\n","    \"\"\"\r\n","    # OPTIONAL: Implement\r\n","    \r\n","    # Hyperparameters\r\n","    learning_rate = 0.001\r\n","    \r\n","    # Build the layers    \r\n","    model = Sequential()\r\n","    # Encoder\r\n","    model.add(GRU(256, input_shape=input_shape[1:], go_backwards=True))\r\n","    model.add(RepeatVector(output_sequence_length))\r\n","    # Decoder\r\n","    model.add(GRU(256, return_sequences=True))\r\n","    model.add(TimeDistributed(Dense(1024, activation='relu')))\r\n","    model.add(Dropout(0.5))\r\n","    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax')))\r\n","\r\n","    # Compile model\r\n","    model.compile(loss=sparse_categorical_crossentropy,\r\n","                  optimizer=Adam(learning_rate),\r\n","                  metrics=['accuracy'])\r\n","    \r\n","    return model"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L4rPeRrEIClZ","executionInfo":{"status":"ok","timestamp":1609759305620,"user_tz":-330,"elapsed":82686,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}},"outputId":"31a52b49-6a1e-4a48-e8f8-78d8a28dfcdd"},"source":["# Reshape the input\r\n","tmp_x = pad(preproc_english_sentences, preproc_french_sentences.shape[1])\r\n","tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2], 1))\r\n","\r\n","# Train and Print prediction(s)\r\n","encdec_rnn_model = encdec_model(\r\n","    tmp_x.shape,\r\n","    preproc_french_sentences.shape[1],\r\n","    len(english_tokenizer.word_index)+1,\r\n","    len(french_tokenizer.word_index)+1)\r\n","\r\n","encdec_rnn_model.summary()\r\n","\r\n","encdec_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=10, validation_split=0.2)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","gru_4 (GRU)                  (None, 256)               198912    \n","_________________________________________________________________\n","repeat_vector (RepeatVector) (None, 21, 256)           0         \n","_________________________________________________________________\n","gru_5 (GRU)                  (None, 21, 256)           394752    \n","_________________________________________________________________\n","time_distributed_8 (TimeDist (None, 21, 1024)          263168    \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 21, 1024)          0         \n","_________________________________________________________________\n","time_distributed_9 (TimeDist (None, 21, 345)           353625    \n","=================================================================\n","Total params: 1,210,457\n","Trainable params: 1,210,457\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","108/108 [==============================] - 11s 78ms/step - loss: 3.0775 - accuracy: 0.4207 - val_loss: 1.7863 - val_accuracy: 0.5661\n","Epoch 2/10\n","108/108 [==============================] - 8s 72ms/step - loss: 1.7289 - accuracy: 0.5655 - val_loss: 1.4353 - val_accuracy: 0.6093\n","Epoch 3/10\n","108/108 [==============================] - 8s 72ms/step - loss: 1.4540 - accuracy: 0.6039 - val_loss: 1.3186 - val_accuracy: 0.6341\n","Epoch 4/10\n","108/108 [==============================] - 8s 72ms/step - loss: 1.3440 - accuracy: 0.6278 - val_loss: 1.2612 - val_accuracy: 0.6510\n","Epoch 5/10\n","108/108 [==============================] - 8s 73ms/step - loss: 1.2810 - accuracy: 0.6428 - val_loss: 1.2093 - val_accuracy: 0.6557\n","Epoch 6/10\n","108/108 [==============================] - 8s 73ms/step - loss: 1.2327 - accuracy: 0.6510 - val_loss: 1.1641 - val_accuracy: 0.6643\n","Epoch 7/10\n","108/108 [==============================] - 8s 73ms/step - loss: 1.1846 - accuracy: 0.6599 - val_loss: 1.1147 - val_accuracy: 0.6730\n","Epoch 8/10\n","108/108 [==============================] - 8s 73ms/step - loss: 1.1494 - accuracy: 0.6666 - val_loss: 1.0691 - val_accuracy: 0.6868\n","Epoch 9/10\n","108/108 [==============================] - 8s 73ms/step - loss: 1.1010 - accuracy: 0.6796 - val_loss: 1.0455 - val_accuracy: 0.6950\n","Epoch 10/10\n","108/108 [==============================] - 8s 73ms/step - loss: 1.0616 - accuracy: 0.6904 - val_loss: 0.9997 - val_accuracy: 0.7082\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f8dacb3b588>"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PO7woMezIGxo","executionInfo":{"status":"ok","timestamp":1609759464523,"user_tz":-330,"elapsed":1156,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}},"outputId":"c5a27226-e4d3-4573-f9b7-ab9fcde32e04"},"source":["print(\"Prediction:\")\r\n","print(logits_to_text(encdec_rnn_model.predict(tmp_x[:1])[0], french_tokenizer))\r\n","\r\n","print(\"\\nCorrect Translation:\")\r\n","print(french_sentences[:1])\r\n","\r\n","print(\"\\nOriginal text:\")\r\n","print(english_sentences[:1])"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Prediction:\n","new jersey est parfois chaud en mois de il est est en en <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n","\n","Correct Translation:\n","[\"new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\"]\n","\n","Original text:\n","['new jersey is sometimes quiet during autumn , and it is snowy in april .']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nNYjVC9DJBeQ","executionInfo":{"status":"ok","timestamp":1609759634566,"user_tz":-330,"elapsed":1072,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}},"outputId":"e7fe2d95-148c-4bd0-ba24-c0cde542166e"},"source":["# make use of embedding and bidrectional model in one.\r\n","def model_final(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\r\n","    \"\"\"\r\n","    Build and train a model that incorporates embedding, encoder-decoder, and bidirectional RNN on x and y\r\n","    :param input_shape: Tuple of input shape\r\n","    :param output_sequence_length: Length of output sequence\r\n","    :param english_vocab_size: Number of unique English words in the dataset\r\n","    :param french_vocab_size: Number of unique French words in the dataset\r\n","    :return: Keras model built, but not trained\r\n","    \"\"\"\r\n","    # TODO: Implement\r\n","\r\n","    # Hyperparameters\r\n","    learning_rate = 0.003\r\n","    \r\n","    # Build the layers    \r\n","    model = Sequential()\r\n","    # Embedding\r\n","    model.add(Embedding(english_vocab_size, 128, input_length=input_shape[1],\r\n","                         input_shape=input_shape[1:]))\r\n","    # Encoder\r\n","    model.add(Bidirectional(GRU(128)))\r\n","    model.add(RepeatVector(output_sequence_length))\r\n","    # Decoder\r\n","    model.add(Bidirectional(GRU(128, return_sequences=True)))\r\n","    model.add(TimeDistributed(Dense(512, activation='relu')))\r\n","    model.add(Dropout(0.5))\r\n","    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax')))\r\n","    model.compile(loss=sparse_categorical_crossentropy,\r\n","                  optimizer=Adam(learning_rate),\r\n","                  metrics=['accuracy'])\r\n","    return model\r\n","print('Final Model Loaded')"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Final Model Loaded\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KR7Gh9vjJkou","executionInfo":{"status":"ok","timestamp":1609759899433,"user_tz":-330,"elapsed":167765,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}},"outputId":"1a799651-aef5-46a0-cad3-0eb0c045aab8"},"source":["def final_predictions(x, y, x_tk, y_tk):\r\n","    \"\"\"\r\n","    Gets predictions using the final model\r\n","    :param x: Preprocessed English data\r\n","    :param y: Preprocessed French data\r\n","    :param x_tk: English tokenizer\r\n","    :param y_tk: French tokenizer\r\n","    \"\"\"\r\n","    # TODO: Train neural network using model_final\r\n","    model = model_final(x.shape,y.shape[1],\r\n","                        len(x_tk.word_index)+1,\r\n","                        len(y_tk.word_index)+1)\r\n","    model.summary()\r\n","    model.fit(x, y, batch_size=1024, epochs=25, validation_split=0.2)\r\n","\r\n","    \r\n","    ## DON'T EDIT ANYTHING BELOW THIS LINE\r\n","    y_id_to_word = {value: key for key, value in y_tk.word_index.items()}\r\n","    y_id_to_word[0] = '<PAD>'\r\n","\r\n","    sentence = 'he saw a old yellow truck'\r\n","    sentence = [x_tk.word_index[word] for word in sentence.split()]\r\n","    sentence = pad_sequences([sentence], maxlen=x.shape[-1], padding='post')\r\n","    sentences = np.array([sentence[0], x[0]])\r\n","    predictions = model.predict(sentences, len(sentences))\r\n","\r\n","    print('Sample 1:')\r\n","    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[0]]))\r\n","    print('Il a vu un vieux camion jaune')\r\n","    print('Sample 2:')\r\n","    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[1]]))\r\n","    print(' '.join([y_id_to_word[np.max(x)] for x in y[0]]))\r\n","\r\n","\r\n","final_predictions(preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer)"],"execution_count":37,"outputs":[{"output_type":"stream","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_2 (Embedding)      (None, 15, 128)           25600     \n","_________________________________________________________________\n","bidirectional (Bidirectional (None, 256)               198144    \n","_________________________________________________________________\n","repeat_vector_1 (RepeatVecto (None, 21, 256)           0         \n","_________________________________________________________________\n","bidirectional_1 (Bidirection (None, 21, 256)           296448    \n","_________________________________________________________________\n","time_distributed_10 (TimeDis (None, 21, 512)           131584    \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 21, 512)           0         \n","_________________________________________________________________\n","time_distributed_11 (TimeDis (None, 21, 345)           176985    \n","=================================================================\n","Total params: 828,761\n","Trainable params: 828,761\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/25\n","108/108 [==============================] - 12s 67ms/step - loss: 3.2356 - accuracy: 0.4162 - val_loss: 1.6110 - val_accuracy: 0.5927\n","Epoch 2/25\n","108/108 [==============================] - 6s 58ms/step - loss: 1.5445 - accuracy: 0.5972 - val_loss: 1.1713 - val_accuracy: 0.6782\n","Epoch 3/25\n","108/108 [==============================] - 6s 58ms/step - loss: 1.1808 - accuracy: 0.6686 - val_loss: 0.9519 - val_accuracy: 0.7202\n","Epoch 4/25\n","108/108 [==============================] - 6s 58ms/step - loss: 0.9863 - accuracy: 0.7102 - val_loss: 0.8469 - val_accuracy: 0.7508\n","Epoch 5/25\n","108/108 [==============================] - 6s 58ms/step - loss: 0.8787 - accuracy: 0.7345 - val_loss: 0.6439 - val_accuracy: 0.7985\n","Epoch 6/25\n","108/108 [==============================] - 6s 58ms/step - loss: 0.6968 - accuracy: 0.7819 - val_loss: 0.5224 - val_accuracy: 0.8359\n","Epoch 7/25\n","108/108 [==============================] - 6s 58ms/step - loss: 0.5770 - accuracy: 0.8169 - val_loss: 0.4139 - val_accuracy: 0.8701\n","Epoch 8/25\n","108/108 [==============================] - 6s 58ms/step - loss: 0.4697 - accuracy: 0.8497 - val_loss: 0.3316 - val_accuracy: 0.8950\n","Epoch 9/25\n","108/108 [==============================] - 6s 58ms/step - loss: 0.3954 - accuracy: 0.8728 - val_loss: 0.2764 - val_accuracy: 0.9154\n","Epoch 10/25\n","108/108 [==============================] - 6s 58ms/step - loss: 0.3604 - accuracy: 0.8876 - val_loss: 0.3812 - val_accuracy: 0.8835\n","Epoch 11/25\n","108/108 [==============================] - 6s 58ms/step - loss: 0.3794 - accuracy: 0.8823 - val_loss: 0.2144 - val_accuracy: 0.9392\n","Epoch 12/25\n","108/108 [==============================] - 6s 59ms/step - loss: 0.2612 - accuracy: 0.9223 - val_loss: 0.1756 - val_accuracy: 0.9511\n","Epoch 13/25\n","108/108 [==============================] - 6s 59ms/step - loss: 0.2218 - accuracy: 0.9342 - val_loss: 0.1826 - val_accuracy: 0.9477\n","Epoch 14/25\n","108/108 [==============================] - 6s 59ms/step - loss: 0.2088 - accuracy: 0.9378 - val_loss: 0.1377 - val_accuracy: 0.9607\n","Epoch 15/25\n","108/108 [==============================] - 6s 59ms/step - loss: 0.1775 - accuracy: 0.9478 - val_loss: 0.1280 - val_accuracy: 0.9633\n","Epoch 16/25\n","108/108 [==============================] - 6s 59ms/step - loss: 0.1583 - accuracy: 0.9534 - val_loss: 0.1264 - val_accuracy: 0.9630\n","Epoch 17/25\n","108/108 [==============================] - 6s 59ms/step - loss: 0.1481 - accuracy: 0.9556 - val_loss: 0.1240 - val_accuracy: 0.9641\n","Epoch 18/25\n","108/108 [==============================] - 6s 59ms/step - loss: 0.1431 - accuracy: 0.9574 - val_loss: 0.1020 - val_accuracy: 0.9699\n","Epoch 19/25\n","108/108 [==============================] - 7s 61ms/step - loss: 0.1246 - accuracy: 0.9630 - val_loss: 0.1053 - val_accuracy: 0.9694\n","Epoch 20/25\n","108/108 [==============================] - 6s 59ms/step - loss: 0.1188 - accuracy: 0.9643 - val_loss: 0.0996 - val_accuracy: 0.9705\n","Epoch 21/25\n","108/108 [==============================] - 6s 59ms/step - loss: 0.1076 - accuracy: 0.9678 - val_loss: 0.0970 - val_accuracy: 0.9714\n","Epoch 22/25\n","108/108 [==============================] - 6s 59ms/step - loss: 0.1112 - accuracy: 0.9667 - val_loss: 0.0955 - val_accuracy: 0.9722\n","Epoch 23/25\n","108/108 [==============================] - 6s 59ms/step - loss: 0.1029 - accuracy: 0.9693 - val_loss: 0.1078 - val_accuracy: 0.9689\n","Epoch 24/25\n","108/108 [==============================] - 6s 59ms/step - loss: 0.1127 - accuracy: 0.9661 - val_loss: 0.1057 - val_accuracy: 0.9693\n","Epoch 25/25\n","108/108 [==============================] - 6s 59ms/step - loss: 0.0979 - accuracy: 0.9707 - val_loss: 0.0783 - val_accuracy: 0.9775\n","WARNING:tensorflow:5 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8dae179378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Sample 1:\n","il a vu un vieux camion jaune <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n","Il a vu un vieux camion jaune\n","Sample 2:\n","new jersey est parfois calme pendant l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n","new jersey est parfois calme pendant l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6YkYucpuKC-b","executionInfo":{"status":"ok","timestamp":1609760065508,"user_tz":-330,"elapsed":1550,"user":{"displayName":"mukesh surywanshi","photoUrl":"","userId":"14209398270961858494"}},"outputId":"20efc03c-a1c0-455d-bc5c-8ffec31f8a84"},"source":["# Save before you run this cell!\r\n","!!jupyter nbconvert *.ipynb"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"[NbConvertApp] WARNING | pattern u'*.ipynb' matched no files\",\n"," 'This application is used to convert notebook files (*.ipynb) to various other',\n"," 'formats.',\n"," '',\n"," 'WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.',\n"," '',\n"," 'Options',\n"," '-------',\n"," '',\n"," 'Arguments that take values are actually convenience aliases to full',\n"," 'Configurables, whose aliases are listed on the help line. For more information',\n"," \"on full configurables, see '--help-all'.\",\n"," '',\n"," '--execute',\n"," '    Execute the notebook prior to export.',\n"," '--allow-errors',\n"," \"    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\",\n"," '--no-input',\n"," '    Exclude input cells and output prompts from converted document. ',\n"," '    This mode is ideal for generating code-free reports.',\n"," '--stdout',\n"," '    Write notebook output to stdout instead of files.',\n"," '--stdin',\n"," \"    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\",\n"," '--inplace',\n"," '    Run nbconvert in place, overwriting the existing notebook (only ',\n"," '    relevant when converting to notebook format)',\n"," '-y',\n"," '    Answer yes to any questions instead of prompting.',\n"," '--clear-output',\n"," '    Clear output of current file and save in place, ',\n"," '    overwriting the existing notebook.',\n"," '--debug',\n"," '    set log level to logging.DEBUG (maximize logging output)',\n"," '--no-prompt',\n"," '    Exclude input and output prompts from converted document.',\n"," '--generate-config',\n"," '    generate default config file',\n"," '--nbformat=<Enum> (NotebookExporter.nbformat_version)',\n"," '    Default: 4',\n"," '    Choices: [1, 2, 3, 4]',\n"," '    The nbformat version to write. Use this to downgrade notebooks.',\n"," '--output-dir=<Unicode> (FilesWriter.build_directory)',\n"," \"    Default: ''\",\n"," '    Directory to write output(s) to. Defaults to output to the directory of each',\n"," '    notebook. To recover previous default behaviour (outputting to the current',\n"," '    working directory) use . as the flag value.',\n"," '--writer=<DottedObjectName> (NbConvertApp.writer_class)',\n"," \"    Default: 'FilesWriter'\",\n"," '    Writer class used to write the  results of the conversion',\n"," '--log-level=<Enum> (Application.log_level)',\n"," '    Default: 30',\n"," \"    Choices: (0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL')\",\n"," '    Set the log level by value or name.',\n"," '--reveal-prefix=<Unicode> (SlidesExporter.reveal_url_prefix)',\n"," \"    Default: u''\",\n"," '    The URL prefix for reveal.js (version 3.x). This defaults to the reveal CDN,',\n"," '    but can be any url pointing to a copy  of reveal.js.',\n"," '    For speaker notes to work, this must be a relative path to a local  copy of',\n"," '    reveal.js: e.g., \"reveal.js\".',\n"," '    If a relative path is given, it must be a subdirectory of the current',\n"," '    directory (from which the server is run).',\n"," '    See the usage documentation',\n"," '    (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-',\n"," '    slideshow) for more details.',\n"," '--to=<Unicode> (NbConvertApp.export_format)',\n"," \"    Default: 'html'\",\n"," '    The export format to be used, either one of the built-in formats',\n"," \"    ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf',\",\n"," \"    'python', 'rst', 'script', 'slides'] or a dotted object name that represents\",\n"," '    the import path for an `Exporter` class',\n"," '--template=<Unicode> (TemplateExporter.template_file)',\n"," \"    Default: u''\",\n"," '    Name of the template file to use',\n"," '--output=<Unicode> (NbConvertApp.output_base)',\n"," \"    Default: ''\",\n"," '    overwrite base name use for output files. can only be used when converting',\n"," '    one notebook at a time.',\n"," '--post=<DottedOrNone> (NbConvertApp.postprocessor_class)',\n"," \"    Default: u''\",\n"," '    PostProcessor class used to write the results of the conversion',\n"," '--config=<Unicode> (JupyterApp.config_file)',\n"," \"    Default: u''\",\n"," '    Full path of a config file.',\n"," '',\n"," 'To see all available configurables, use `--help-all`',\n"," '',\n"," 'Examples',\n"," '--------',\n"," '',\n"," '    The simplest way to use nbconvert is',\n"," '    ',\n"," '    > jupyter nbconvert mynotebook.ipynb',\n"," '    ',\n"," '    which will convert mynotebook.ipynb to the default format (probably HTML).',\n"," '    ',\n"," '    You can specify the export format with `--to`.',\n"," \"    Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides'].\",\n"," '    ',\n"," '    > jupyter nbconvert --to latex mynotebook.ipynb',\n"," '    ',\n"," '    Both HTML and LaTeX support multiple output templates. LaTeX includes',\n"," \"    'base', 'article' and 'report'.  HTML includes 'basic' and 'full'. You\",\n"," '    can specify the flavor of the format used.',\n"," '    ',\n"," '    > jupyter nbconvert --to html --template basic mynotebook.ipynb',\n"," '    ',\n"," '    You can also pipe the output to stdout, rather than a file',\n"," '    ',\n"," '    > jupyter nbconvert mynotebook.ipynb --stdout',\n"," '    ',\n"," '    PDF is generated via latex',\n"," '    ',\n"," '    > jupyter nbconvert mynotebook.ipynb --to pdf',\n"," '    ',\n"," '    You can get (and serve) a Reveal.js-powered slideshow',\n"," '    ',\n"," '    > jupyter nbconvert myslides.ipynb --to slides --post serve',\n"," '    ',\n"," '    Multiple notebooks can be given at the command line in a couple of ',\n"," '    different ways:',\n"," '    ',\n"," '    > jupyter nbconvert notebook*.ipynb',\n"," '    > jupyter nbconvert notebook1.ipynb notebook2.ipynb',\n"," '    ',\n"," '    or you can specify the notebooks list in a config file, containing::',\n"," '    ',\n"," '        c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]',\n"," '    ',\n"," '    > jupyter nbconvert --config mycfg.py',\n"," '']"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"5mDbvdJgLUF0"},"source":[""],"execution_count":null,"outputs":[]}]}